---
layout:     post
title:      Lending Club
subtitle:   Predict Lenders’ Future Repayment Behave
date:       2018-12-11
author:     Group 11
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Lending Club
    - Machine Learning
---

# Introduction
LendingClub is a US peer-to-peer lending company, the company operates an online lending platform that enables borrowers to obtain a loan, and investors to purchase notes backed by payments made on loans. Borrowers can take out loans from Lending Club worth up to as much as $40,000. Investors purchase notes, which are assets corresponding to fractions of these loans. Different notes correspond to different loans and borrowers. There are several pieces of information pertaining to the borrower which can serve as potential indicators to his/her timeliness in repaying the loan. One of the ways in which an investor can determine which borrowers are riskiest is through the question and answer section on their application, which provides the investor with information on the borrow and the purpose of the requested loan. The goal of our analysis is to use other data (mostly numerical) to create an empirical prediction as to how likely a borrower is to repay his/her loan on time.
We got the data from: https://www.kaggle.com/wordsforthewise/lending-club.

# Motivation
Our objective will be to study what factors would influence the company's decision to lend money to clients, and to predict lenders’ future repayment performance. 

# Preprocessing
#### Brief Introduction of Data
The files we obtained have complete loan data for all loans issued through the 2007-2017, including the current loan status (Current, Late, Fully Paid, etc.) and latest payment information. The file containing loan data through the "present" contains complete loan data for all loans issued through the previous completed calendar quarter. Additional features include credit scores, number of finance inquiries, address including zip codes, and state, and collections among others. The file contains 136 columns (variables) and each column contains about 1.5 million data. Some columns have null value and it exists empty column which means column only contain column name, and the dataset is imbalanced, i.e. around 9/10 instances are good status and around 1/10 instances are bad status. 
#### Redefine Label
The column named “Loan Status” which describes each lender’s loan status, the attribute contains 10 classes as shown as below:
![gitment]({{ '/img/labels.png'|prepend:site.baseurl}})
We classify “Current”, “Fully Paid” and “Does not meet the credit policy. Status:Fully Paid” as good status, and others as bad status, so it becomes a binary label as below:
![gitment]({{ '/img/binaryLabel.png'|prepend:site.baseurl}})
#### Data Cleaning
- **Remove predictors that are obviously useless**
	
	Some cannot be used to fit model like “url”, "zip_code" and etc.; 
	Some do not contains values or have only one value, like “collection_12_mths_ex_med”.

- **Convert dates from string value to integer value**

	Like "term" column contains two classes which are "36 months" and "60 months", we replace them with integers 36 and 60.
- **Convert categorical variables to dummy variables**
- **Replace missing values with the column average**
- **Replace missing values with the column average**
- **Delete columns with 0 variance**
- **Normalize the data**

#### Generate Two Datasets
After doing data cleaning, we get a dataset called "cleaned_data" ready to use. Since the dataset cantains total 136 attributes, it's not easy for data visulization and it's very time consuming when training models. we decide to use PCA to do dimension reduction. However, PCA would make all model be lack of interpretability because the new dataset generated by PCA doesn't contain attribute information. Sometimes people would like to know what particular attribute or attributes influence the final results more, hence we decide to apply algorithms to two datasets, one is a dataset with no PCA operation, and the another one is a dataset with PCA operation.
- **Dataset with no PCA operation**
	
	We remove high correlated attributes of the "cleaned_data", and named it as "before_PCA_data".

- **Dataset with PCA operation**

	We apply PCA on the "cleaned_data", and named it as "after_PCA_data".


