---
layout:     post
title:      Lending Club
subtitle:   Predict Lenders’ Future Repayment Behave
date:       2018-12-11
author:     Group 11
header-img: img/post-bg-hacker.jpg
catalog: true
tags:
    - Lending Club
    - Machine Learning
---

# Introduction
LendingClub is a US peer-to-peer lending company, the company operates an online lending platform that enables borrowers to obtain a loan, and investors to purchase notes backed by payments made on loans. Borrowers can take out loans from Lending Club worth up to as much as $40,000. Investors purchase notes, which are assets corresponding to fractions of these loans. Different notes correspond to different loans and borrowers. There are several pieces of information pertaining to the borrower which can serve as potential indicators to his/her timeliness in repaying the loan. One of the ways in which an investor can determine which borrowers are riskiest is through the question and answer section on their application, which provides the investor with information on the borrow and the purpose of the requested loan. The goal of our analysis is to use other data (mostly numerical) to create an empirical prediction as to how likely a borrower is to repay his/her loan on time.
We got the data from: https://www.kaggle.com/wordsforthewise/lending-club.

# Motivation
Our objective will be to study what factors would influence the company's decision to lend money to clients, and to predict borrowers’ future repayment performance. 

# Preprocessing
#### Brief Introduction of Data
The files we obtained have complete loan data for all loans issued through the 2007-2017, including the current loan status (Current, Late, Fully Paid, etc.) and latest payment information. The file containing loan data through the "present" contains complete loan data for all loans issued through the previous completed calendar quarter. Additional features include credit scores, number of finance inquiries, address including zip codes, and state, and collections among others. The file contains 136 columns (variables) and each column contains about 1.5 million data. Some columns have null value and it exists empty column which means column only contain column name, and the dataset is imbalanced, i.e. around 9/10 instances are good status and around 1/10 instances are bad status. 
#### Redefine Label
The column named “Loan Status” which describes each lender’s loan status, the attribute contains 10 classes as shown as below:
![gitment]({{ '/img/labels.png'|prepend:site.baseurl}})
We classify “Current”, “Fully Paid” and “Does not meet the credit policy. Status:Fully Paid” as good status, and others as bad status, so it becomes a binary label as below:
![gitment]({{ '/img/binaryLabels.png'|prepend:site.baseurl}})
#### Data Cleaning
- **Remove predictors that are obviously useless**
	
	Some cannot be used to fit model like “url”, "zip_code" and etc.; 
	Some do not contains values or have only one value, like “collection_12_mths_ex_med”.

- **Convert dates from string value to integer value**

	Like "term" column contains two classes which are "36 months" and "60 months", we replace them with integers 36 and 60.
- **Convert categorical variables to dummy variables**
- **Replace missing values with the column average**
- **Replace missing values with the column average**
- **Delete columns with 0 variance**
- **Remove high correlated predictors**
- **Normalize the data**
- **Downsample the data**
	
	After ramdomly choose 25K instances of each labels, we get balanced dataset cantains 50K instances.
	![gitment]({{ '/img/balanced.png'|prepend:site.baseurl}})
136 -> 75 -> 68 -> 45
#### Generate Two Datasets
After doing data cleaning, we get a dataset called "cleaned_data" ready to use. Since the dataset cantains total 136 attributes, it's not easy for data visulization and it's very time consuming when training models. we decide to use PCA to do dimension reduction. However, PCA would make all models be lack of interpretability because the new dataset generated by PCA doesn't contain attribute information. Sometimes people would like to know what particular attribute or attributes influence the final results more, hence we decide to apply algorithms to two datasets, one is a dataset with no PCA operation, and the another one is a dataset with PCA operation. We have three main purpose for doing PCA. The first one is reducing the dimension of dataset so that we could train models faster. The second one is data visulization. After PCA, we could plot the first two principle components to show the potetion boundary. It does a great favour when applying SVM algorithm. The third one is avoiding overfitting.
![gitment]({{ '/img/pca_plot_1.png'|prepend:site.baseurl}})
![gitment]({{ '/img/pca_plot_2.png'|prepend:site.baseurl}})
As you can see from the two pictures, the boundary looks like a circle or radial. We can give up on trying fitting linear kernal to the dataset when doing SVM.
- **Dataset with no PCA operation**
	
	We named it as "clean_data_with_target".

- **Dataset with PCA operation**
	
	
	We apply PCA on the "cleaned_data", based on the result, we chose the first 45 components as our predictors (the first 45 components explained 95% variance of the "clean_data_with_target" dataset) and named the dataset as "clean_data_with_target_after_PCA".

#### Model Selection
For each method, we seperate the dataset into 70% as training set, and 30% as testing set.
- **KNN**

	We take different k values range from 1 to 35, and for each k, we use 3-fold-cross-validation on training set to train KNN model and record the train accuracy, test accuracy and specifility accuracy.
	The accuracies rates of KNN classifier with different values of K are as follow:
	- **Before PCA**
		![gitment]({{ '/img/knn_before_pca.png'|prepend:site.baseurl}})
		Hence we decide to use K = 11 for training model to test before pca testing set.
	- **After PCA**
		![gitment]({{ '/img/knn_after_pca.png'|prepend:site.baseurl}})
		Hence we decide to use K = 16 for training model to test after pca testing set.
- **Decision Tree**

	We take different depth values range from 1 to 30, and for each depth, we use 3-fold-cross-validation on training set to train KNN model and record the train accuracy, test accuracy and specifility accuracy.
	The accuracies rates of Decision Tree classifier with different values of depth are as follow:
	- **Before PCA**
		![gitment]({{ '/img/dt_before_pca.png'|prepend:site.baseurl}})
		Hence we decide to train the model with depth = 5 to test before pca testing set.
	- **After PCA**
		![gitment]({{ '/img/dt_after_pca.png'|prepend:site.baseurl}})
		Hence we decide to train the model with depth = 5 to test after pca testing set.
- **Random Forest**

	We test for different parameter combinations such as 
	
	- **Number of Trees**
	- **Number of Features to Consider at Every Split**
	- **Maximum Number of Levels in Tree**
	- **Minimum number of samples required to split a node**
    - **Minimum number of samples required at each leaf node**
	
	"Best" parameters:

	- **Before PCA**
		![gitment]({{ '/img/rf_before_pca_parameters.png'|prepend:site.baseurl}})
		Hence we decide to train the model with these parameters to test before pca testing set.
	- **After PCA**
		![gitment]({{ '/img/rf_after_pca_parameters.png'|prepend:site.baseurl}})
		Hence we decide to train the model with these parameters to test after pca testing set.
	

- **Adaboost with Decision Tree**

	We test for different parameter combinations such as 
	
	- **Number of Trees**
	- **Learning Rate**

	"Best" parameters:

	- **Before PCA**
		![gitment]({{ '/img/ada_before_pca_parameters.png'|prepend:site.baseurl}})
		Hence we decide to train the model with these parameters to test before pca testing set.
	- **After PCA**
		![gitment]({{ '/img/ada_after_pca_parameters.png'|prepend:site.baseurl}})
		Hence we decide to train the model with these parameters to test after pca testing set.

- **SVM**

	We test for different parameter combinations such as 
	
	- **Kernels**
	- **Penalty Parameters**
	- **Kernel Coefficients**
	- **Degrees(Only combined with "Poly" Kernel)**
	
	"Best" parameters:
	
	- **Before PCA**
		- **Kernel is rbf**
			![gitment]({{ '/img/svm_before_pca_rbf.png'|prepend:site.baseurl}})
			Hence we decide to train the model with these parameters to test after pca testing set.
		- **Kernel is poly**
			![gitment]({{ '/img/svm_before_pca_poly.png'|prepend:site.baseurl}})
			Hence we decide to train the model with these parameters to test after pca testing set.
		- **Kernel is sigmoid**
			![gitment]({{ '/img/svm_before_pca_sigmoid.png'|prepend:site.baseurl}})
			Hence we decide to train the model with these parameters to test after pca testing set.
	- **After PCA**
		- **Kernel is rbf**
			![gitment]({{ '/img/svm_after_pca_rbf.png'|prepend:site.baseurl}})
			Hence we decide to train the model with these parameters to test after pca testing set.
		- **Kernel is poly**
			![gitment]({{ '/img/svm_after_pca_poly.png'|prepend:site.baseurl}})
			Hence we decide to train the model with these parameters to test after pca testing set.
		- **Kernel is sigmoid**
			![gitment]({{ '/img/svm_after_pca_sigmoid.png'|prepend:site.baseurl}})
			Hence we decide to train the model with these parameters to test after pca testing set.
		
	

- **Neural Network**

	We test for different parameter combinations such as 
	
	- **Activations**
	- **Hidden layer sizes**
	- **Solvers**
	- **Alphas**
	- **Learning Rates**

	"Best" parameters:

	- **Before PCA**
		![gitment]({{ '/img/nn_before_pca_parameters.png'|prepend:site.baseurl}})
		Hence we decide to train the model with these parameters to test before pca testing set.
	- **After PCA**
		![gitment]({{ '/img/nn_after_pca_parameters.png'|prepend:site.baseurl}})
		Hence we decide to train the model with these parameters to test after pca testing set.

#### Results

#### Conclusion
In this project, we utilize many statistical methods we learned in class including crossvalidation, decision tree, random forest, adaboost with tree, support vector machine, nueral network.

We also realize the effect of the balance of a dataset. If the training data set with a large amount of good behavior observations, the model we obtained performs well on predicting good behavior. However, we concern more on bad behavior prediction in this experiment so the dataset should contain more bad behavior observations.

We believe by applying our strategies, the loan companies will be able to easier in making decisions to decrease default rate of loan, make business decisions, improve loan issue time cycle, and eventually increase benefit.
